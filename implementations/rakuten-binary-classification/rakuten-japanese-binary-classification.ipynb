{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "import MeCab\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rakuten Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train sample: 3.400.000  \n",
    "Test sample: 400.000  \n",
    "Tokenizer: SentencePiece 32k model, trained on random 340.000 samples from the Training set  \n",
    "Vectorizer: TFIDF  \n",
    "Classifier: Logistics Regression, C=10, solver=lbfgs, penalty=l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/rakuten-sentiment-dataset/binary/binary_train.csv', header=None)\n",
    "df_test = pd.read_csv('../data/rakuten-sentiment-dataset/binary/binary_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>^^</td>\n",
       "      <td>いいです＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>×</td>\n",
       "      <td>××××××××××××××××××××××××××××××××××××××××××××××...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>ｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "      <td>いいいいいいいいいいいいいいいいいいいいいいいいいいいいいいぞ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!まいった！</td>\n",
       "      <td>そうりょうむりょうじゃないーーーーーー！やられた！</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1                                                  2\n",
       "0  1        ^^                いいです＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾\n",
       "1  1         ×  ××××××××××××××××××××××××××××××××××××××××××××××...\n",
       "2  1                            ｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｋ\n",
       "3  2         -                    いいいいいいいいいいいいいいいいいいいいいいいいいいいいいいぞ\n",
       "4  1  !!!まいった！                          そうりょうむりょうじゃないーーーーーー！やられた！"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples:  3400000\n",
      "Total testing samples:  400000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total training samples: \", len(df_train))\n",
    "print(\"Total testing samples: \", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='./sp-model-32000-340k.model')\n",
    "\n",
    "def tokenize(text):\n",
    "    tokenized = sp.encode(text, out_type=str)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples:  3400000\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = df_train[2], df_train[0]\n",
    "print(\"Total train samples: \", len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVect = TfidfVectorizer(tokenizer=tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Vect time (SentencePiece):  223.09809064865112\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "X_train_tfidf = tfidfVect.fit_transform(X_train)\n",
    "end = time.time()\n",
    "print(\"TFIDF Vect time (SentencePiece): \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train_tfidf, open(\"tfidf_features.pickle\", \"wb\"))\n",
    "pickle.dump(tfidfVect, open(\"tfidf_vectorizer.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Vectorizer from Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVect = pickle.load(open(\"tfidf_vectorizer.pickle\", \"rb\"))\n",
    "X_train_tfidf = pickle.load(open(\"tfidf_features.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (LR-SP):  80.27098107337952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrejpn19/ENTER/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = LogisticRegression(random_state=0, C=10, penalty='l2', solver='lbfgs').fit(X_train_tfidf, y_train)\n",
    "end = time.time()\n",
    "print(\"Training time (LR-SP): \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tips to try (out of many) that might help the algorithm to converge are:\n",
    "- Increase the Number of Iterations: \n",
    "- Try Different Optimizer https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions/52388406#52388406\n",
    "- Scale Your Data https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "- Add Engineered Features https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/\n",
    "- Data Pre-processing \n",
    "    - https://datascience.stackexchange.com/questions/80421/very-low-cross-val-score-for-regression-with-big-corr-between-feature-and-res/80422#80422\n",
    "    - https://towardsdatascience.com/feature-engineering-for-machine-learning-3a5e293a5114\n",
    "- Add More Data https://www.quora.com/How-do-you-determine-sample-size-for-machine-learning-classification/answer/Yahya-Almardeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples:  3400000\n",
      "Train Error rate (LR-SP) 6.7895882352941195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93   1696788\n",
      "           2       0.93      0.93      0.93   1703212\n",
      "\n",
      "    accuracy                           0.93   3400000\n",
      "   macro avg       0.93      0.93      0.93   3400000\n",
      "weighted avg       0.93      0.93      0.93   3400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Total train samples: \", len(X_train))\n",
    "\n",
    "predicted = clf.predict(X_train_tfidf)\n",
    "print(\"Train Error rate (LR-SP)\", (1-np.mean(predicted == y_train))*100)\n",
    "print(classification_report(predicted, y_train, labels=[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples:  400000\n",
      "Error rate (LR-SP) 7.065750000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.93      0.93      0.93    199665\n",
      "           2       0.93      0.93      0.93    200335\n",
      "\n",
      "    accuracy                           0.93    400000\n",
      "   macro avg       0.93      0.93      0.93    400000\n",
      "weighted avg       0.93      0.93      0.93    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = df_test[2], df_test[0]\n",
    "print(\"Total test samples: \", len(X_test))\n",
    "\n",
    "X_test_tfidf = tfidfVect.transform(X_test)\n",
    "predicted = clf.predichttp://34.66.19.11:5000/notebooks/research/rakuten-binary-classification/rakuten-japanese-binary-classification.ipynb#t(X_test_tfidf)\n",
    "print(\"Error rate (LR-SP)\", (1-np.mean(predicted == y_test))*100)\n",
    "print(classification_report(predicted, y_test, labels=[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
