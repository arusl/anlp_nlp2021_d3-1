{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "import MeCab\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/rakuten-sentiment-dataset/full/full_train.csv', header=None)\n",
    "df_test = pd.read_csv('../data/rakuten-sentiment-dataset/full/full_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>^^</td>\n",
       "      <td>いいです＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>ｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!まいった！</td>\n",
       "      <td>そうりょうむりょうじゃないーーーーーー！やられた！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>////////////////////////////////////////</td>\n",
       "      <td>ｐｐｐ・・・・・・・・・・・・・/////////////////////////////</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>...こういうのって、こんなもの？</td>\n",
       "      <td>つぼみがついてましたが、ちいさくてくさってました。もうかいません。</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                         1  \\\n",
       "0  2                                        ^^   \n",
       "1  1                                             \n",
       "2  1                                  !!!まいった！   \n",
       "3  3  ////////////////////////////////////////   \n",
       "4  1                         ...こういうのって、こんなもの？   \n",
       "\n",
       "                                               2  \n",
       "0            いいです＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾＾  \n",
       "1              ｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｂｋ  \n",
       "2                      そうりょうむりょうじゃないーーーーーー！やられた！  \n",
       "3  ｐｐｐ・・・・・・・・・・・・・/////////////////////////////  \n",
       "4              つぼみがついてましたが、ちいさくてくさってました。もうかいません。  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples:  4000000\n",
      "Total testing samples:  500000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total training samples: \", len(df_train))\n",
    "print(\"Total testing samples: \", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='./sp-model-32000-340k.model')\n",
    "\n",
    "def tokenize(text):\n",
    "    tokenized = sp.encode(text, out_type=str)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples:  4000000\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = df_train[2], df_train[0]\n",
    "print(\"Total train samples: \", len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Vect time (SentencePiece):  301.7839548587799\n"
     ]
    }
   ],
   "source": [
    "tfidfVect = TfidfVectorizer(tokenizer=tokenize)\n",
    "start = time.time()\n",
    "X_train_tfidf = tfidfVect.fit_transform(X_train)\n",
    "end = time.time()\n",
    "print(\"TFIDF Vect time (SentencePiece): \", end-start)\n",
    "pickle.dump(X_train_tfidf, open(\"tfidf_features.pickle\", \"wb\"))\n",
    "pickle.dump(tfidfVect, open(\"tfidf_vectorizer.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidfVect = pickle.load(open(\"tfidf_vectorizer.pickle\", \"rb\"))\n",
    "# X_train_tfidf = pickle.load(open(\"tfidf_features.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (LR-SP):  332.0775535106659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrejpn19/ENTER/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf = LogisticRegression(random_state=0, C=10, penalty='l2', solver='lbfgs').fit(X_train_tfidf, y_train)\n",
    "end = time.time()\n",
    "print(\"Training time (LR-SP): \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples:  4000000\n",
      "Train Error rate (LR-SP) 46.863049999999994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.65      0.67    850117\n",
      "           2       0.48      0.48      0.48    803633\n",
      "           3       0.41      0.43      0.42    770969\n",
      "           4       0.37      0.49      0.42    602204\n",
      "           5       0.71      0.58      0.64    973077\n",
      "\n",
      "    accuracy                           0.53   4000000\n",
      "   macro avg       0.53      0.52      0.53   4000000\n",
      "weighted avg       0.55      0.53      0.54   4000000\n",
      "\n",
      "0.61495075\n"
     ]
    }
   ],
   "source": [
    "print(\"Total train samples: \", len(X_train))\n",
    "\n",
    "predicted = clf.predict(X_train_tfidf)\n",
    "print(\"Train Error rate (LR-SP)\", (1-np.mean(predicted == y_train))*100)\n",
    "print(classification_report(predicted, y_train, labels=[1,2,3,4,5]))\n",
    "print(mean_absolute_error(y_train, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples:  500000\n",
      "Error rate (LR-SP) 47.608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.65      0.67    106413\n",
      "           2       0.47      0.47      0.47    100344\n",
      "           3       0.40      0.42      0.41     96532\n",
      "           4       0.36      0.48      0.41     74888\n",
      "           5       0.70      0.58      0.63    121823\n",
      "\n",
      "    accuracy                           0.52    500000\n",
      "   macro avg       0.52      0.52      0.52    500000\n",
      "weighted avg       0.54      0.52      0.53    500000\n",
      "\n",
      "0.622832\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = df_test[2], df_test[0]\n",
    "print(\"Total test samples: \", len(X_test))\n",
    "\n",
    "X_test_tfidf = tfidfVect.transform(X_test)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print(\"Error rate (LR-SP)\", (1-np.mean(predicted == y_test))*100)\n",
    "print(classification_report(predicted, y_test, labels=[1,2,3,4,5]))\n",
    "print(mean_absolute_error(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
